import streamlit as st
import torch
from transformers import CLIPProcessor, CLIPModel
from PIL import Image
import re

# --- 1. è¨­å®š & ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ ---
st.set_page_config(page_title="X Post Analyzer", layout="wide")

@st.cache_resource
def load_model():
    # OpenAIã®CLIPãƒ¢ãƒ‡ãƒ«ï¼ˆè»½é‡ç‰ˆï¼‰ã‚’ãƒ­ãƒ¼ãƒ‰
    model_name = "openai/clip-vit-base-patch32"
    model = CLIPModel.from_pretrained(model_name)
    processor = CLIPProcessor.from_pretrained(model_name)
    return model, processor

model, processor = load_model()

# --- 2. ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ ---

def analyze_text(text):
    score_mod = 0
    feedback = []
    
    # URLãƒã‚§ãƒƒã‚¯ (ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ä¸Šã€æœ¬æ–‡ã®URLã¯ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã‚’ä¸‹ã’ã‚‹è¦å› )
    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)
    if urls:
        score_mod -= 30
        feedback.append("âš ï¸ **URLãŒå«ã¾ã‚Œã¦ã„ã¾ã™**: å¤–éƒ¨ãƒªãƒ³ã‚¯ã¯ãƒªãƒ—ãƒ©ã‚¤æ¬„ã«è²¼ã‚‹ã“ã¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ï¼ˆã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ä½ä¸‹ãƒªã‚¹ã‚¯å¤§ï¼‰ã€‚")
    
    # ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ãƒã‚§ãƒƒã‚¯
    hashtags = re.findall(r'#\w+', text)
    if len(hashtags) > 5:
        score_mod -= 10
        feedback.append("âš ï¸ **ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°éå¤š**: 5å€‹ä»¥ä¸Šã¯ã‚¹ãƒ‘ãƒ åˆ¤å®šã•ã‚Œã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚")
    elif len(hashtags) == 0:
        score_mod -= 5
        feedback.append("â„¹ï¸ ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚é–¢é€£ã‚¿ã‚°ã‚’1-2å€‹ã¤ã‘ã‚‹ã¨æ¤œç´¢æµå…¥ãŒå¢—ãˆã¾ã™ã€‚")
    
    # ç–‘å•å½¢ãƒã‚§ãƒƒã‚¯ (å¯¾è©±ã‚’ä¿ƒã™ãŸã‚åŠ ç‚¹)
    if "?" in text or "ï¼Ÿ" in text:
        score_mod += 10
        feedback.append("âœ… **å¯¾è©±ä¿ƒé€²**: ç–‘å•å½¢ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€ãƒªãƒ—ãƒ©ã‚¤ã‚’èª˜ç™ºã—ã‚„ã™ããªã£ã¦ã„ã¾ã™ã€‚")

    # é•·æ–‡ãƒã‚§ãƒƒã‚¯ (æ¥µç«¯ã«çŸ­ã„ã¨ã‚¹ãƒ«ãƒ¼ã•ã‚Œã‚„ã™ã„)
    if len(text) < 10 and not urls: # URLã®ã¿æŠ•ç¨¿ã¯åˆ¥ã§åˆ¤å®šæ¸ˆã¿
        score_mod -= 10
        feedback.append("âš ï¸ **ãƒ†ã‚­ã‚¹ãƒˆä¸è¶³**: æ–‡ç« ãŒçŸ­ã™ãã¾ã™ã€‚æ–‡è„ˆï¼ˆã‚¹ãƒˆãƒ¼ãƒªãƒ¼ï¼‰ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
        
    return score_mod, feedback, len(urls) > 0

def analyze_image_with_clip(image, target_keywords):
    # CLIPã§ç”»åƒã‚’è§£æ
    
    # 1. NSFW / Safety Check
    # ç–‘ä¼¼çš„ã«CLIPã§ã€Œå®‰å…¨ã€ã‹ã€Œç–‘ã‚ã—ã„ã€ã‹ã‚’ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆåˆ†é¡
    safety_prompts = ["safe content", "nsfw content", "explicit content", "gore"]
    
    # 2. Cluster Target Check (SimClusters)
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç‹™ã£ã¦ã„ã‚‹ã‚¸ãƒ£ãƒ³ãƒ«ï¼ˆä¾‹: anime, carï¼‰ã¨ã—ã¦èªè­˜ã•ã‚Œã‚‹ã‹
    sim_prompts = [p.strip() for p in target_keywords.split(",")] if target_keywords else ["general image"]
    
    all_prompts = safety_prompts + sim_prompts
    
    inputs = processor(text=all_prompts, images=image, return_tensors="pt", padding=True)
    
    with torch.no_grad():
        outputs = model(**inputs)
    
    # ç¢ºç‡è¨ˆç®—
    logits_per_image = outputs.logits_per_image
    probs = logits_per_image.softmax(dim=1).cpu().numpy()[0]
    
    results = dict(zip(all_prompts, probs))
    
    # åˆ¤å®š
    is_unsafe = (results["nsfw content"] + results["explicit content"] + results.get("gore", 0)) > results["safe content"]
    
    return results, is_unsafe

# --- 3. UIæ§‹ç¯‰ ---

st.title("ğŸš€ X (Twitter) Algorithm Post Scorer")
st.markdown("Githubã§å…¬é–‹ã•ã‚ŒãŸã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ç‰¹æ€§ï¼ˆãƒ¡ãƒ‡ã‚£ã‚¢å„ªé‡ã€URLå†·é‡ã€SimClustersãªã©ï¼‰ã‚’å…ƒã«ã€æŠ•ç¨¿ã®ã€Œä¼¸ã³ã‚„ã™ã•ã€ã‚’è¨ºæ–­ã—ã¾ã™ã€‚")

col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("ğŸ“ æŠ•ç¨¿å†…å®¹ä½œæˆ")
    post_text = st.text_area("æœ¬æ–‡ã‚’å…¥åŠ›", height=150, placeholder="ã“ã“ã«æŠ•ç¨¿äºˆå®šã®æ–‡ç« ã‚’å…¥åŠ›...")
    uploaded_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (æ¨å¥¨)", type=["png", "jpg", "jpeg", "webp"])
    
    st.markdown("---")
    st.subheader("ğŸ¯ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨­å®š (SimClusters)")
    st.markdown("AIã«ã©ã®ã‚ˆã†ã«èªè­˜ã•ã‚ŒãŸã„ã§ã™ã‹ï¼Ÿï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å…¥åŠ›ï¼‰")
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼æ§˜ã®èˆˆå‘³ã«åˆã‚ã›ã¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
    target_tags = st.text_input("ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", value="anime girl, high quality, illustration, sports car")

with col2:
    st.subheader("ğŸ“Š è¨ºæ–­çµæœ")
    
    if st.button("ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è¨ºæ–­ã‚’å®Ÿè¡Œ", type="primary"):
        base_score = 50 # åŸºæº–ç‚¹
        text_mod, text_fb, has_url = analyze_text(post_text)
        
        image_score = 0
        image_fb = []
        is_nsfw = False
        detected_tags = {}
        
        # ç”»åƒåˆ†æ
        if uploaded_file:
            image = Image.open(uploaded_file)
            
            # ç”»åƒãŒã‚ã‚‹ã ã‘ã§ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ä¸Šã¯æœ‰åˆ© (+20ç‚¹)
            image_score += 25 
            image_fb.append("âœ… **ãƒ¡ãƒ‡ã‚£ã‚¢æ·»ä»˜**: ç”»åƒ/å‹•ç”»ä»˜ãæŠ•ç¨¿ã¯ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚ˆã‚Š2å€ä»¥ä¸Šæ‹¡æ•£ã•ã‚Œã‚„ã™ããªã‚Šã¾ã™ã€‚")
            
            # CLIPè§£æ
            detected_tags, is_nsfw = analyze_image_with_clip(image, target_tags)
            
            if is_nsfw:
                image_score = -100 # å¼·åˆ¶çš„ã«ã‚¹ã‚³ã‚¢ã‚’ä¸‹ã’ã‚‹
                image_fb.append("â›” **SHADOWBAN RISK**: AIãŒã“ã®ç”»åƒã‚’ã€ŒNSFWï¼ˆã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–ï¼‰ã€ã¨åˆ¤å®šã™ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ã€‚æŠ•ç¨¿ã¯æ§ãˆã‚‹ã‹ã€ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚")
            else:
                image_fb.append("âœ… **Safety Check**: AIåˆ¤å®šã¯ã€ŒSafeã€ã§ã™ã€‚")
                
                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé©åˆåº¦ãƒã‚§ãƒƒã‚¯
                top_tag = max(target_tags.split(","), key=lambda t: detected_tags.get(t.strip(), 0))
                top_prob = detected_tags.get(top_tag.strip(), 0)
                
                if top_prob > 0.2: # é–¾å€¤
                    image_score += 15
                    image_fb.append(f"âœ… **ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼é©åˆ**: AIã¯ã“ã®ç”»åƒã‚’ã€Œ{top_tag.strip()}ã€ã¨å¼·ãèªè­˜ã—ã¦ã„ã¾ã™ã€‚ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã«å±Šãã‚„ã™ã„ã§ã™ã€‚")
                else:
                    image_fb.append(f"âš ï¸ **èªè­˜ä¸ååˆ†**: AIã¯æŒ‡å®šã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆ{top_tag.strip()}ï¼‰ã®ç‰¹å¾´ã‚’ã‚ã¾ã‚Šæ¤œå‡ºã§ãã¦ã„ã¾ã›ã‚“ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„æ§‹å›³ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")

        else:
            image_score -= 10
            image_fb.append("âš ï¸ **ç”»åƒãªã—**: ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®æŠ•ç¨¿ã¯æ‹¡æ•£åŠ›ãŒä½ããªã‚Šã¾ã™ã€‚")

        # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
        total_score = base_score + text_mod + image_score
        total_score = max(0, min(100, total_score)) # 0-100ã®ç¯„å›²ã«åã‚ã‚‹
        
        # çµæœè¡¨ç¤º
        if is_nsfw:
            st.error(f"ã‚¹ã‚³ã‚¢: 0 / 100 (å±é™º)")
        elif total_score > 80:
            st.success(f"ã‚¹ã‚³ã‚¢: {total_score} / 100 (Excellent!)")
        elif total_score > 50:
            st.warning(f"ã‚¹ã‚³ã‚¢: {total_score} / 100 (Good)")
        else:
            st.error(f"ã‚¹ã‚³ã‚¢: {total_score} / 100 (Needs Improvement)")
            
        st.progress(total_score / 100)
        
        st.markdown("### ğŸ“‹ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ")
        
        st.write("#### ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ")
        for fb in text_fb:
            st.markdown(fb)
            
        st.write("#### ç”»åƒãƒ»ãƒ¡ãƒ‡ã‚£ã‚¢åˆ†æ")
        for fb in image_fb:
            st.markdown(fb)
            
        if uploaded_file and not is_nsfw:
            st.write("#### ğŸ‘ï¸ AIã®èªè­˜ç¢ºç‡ (CLIP)")
            # ã‚°ãƒ©ãƒ•åŒ–
            st.bar_chart(detected_tags)
